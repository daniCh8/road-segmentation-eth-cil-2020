{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We'll train each model in a different cell. This is because in every cell we can reset the environment, freeing the hardware from caches and overheads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from config import config\n",
    "from model import NNet\n",
    "from utils import single_model_training\n",
    "import numpy as np\n",
    "\n",
    "net_to_train = config['net_types'][0]\n",
    "net = NNet(net_type=net_to_train)\n",
    "single_model_training(model=net,\n",
    "                      save_path=config[net_to_train]['checkpoint'],\n",
    "                      additional_epochs=config['additional_epochs'],\n",
    "                      competition_epochs=config['competition_epochs'],\n",
    "                      b_size=config[net_to_train]['batch_size'],\n",
    "                      loss=config['loss'],\n",
    "                      l_rate_a=config['learning_rate_additional_data'],\n",
    "                      l_rate_b=config['learning_rate_competition_data'])\n",
    "\n",
    "predictions = net.predict_test_data()\n",
    "np.save(file=config[net_to_train]['predictions_path'], arr=predictions)\n",
    "print('saved model predictions at path: {}'.format(config[net_to_train]['predictions_path']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URES-Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from config import config\n",
    "from model import NNet\n",
    "from utils import single_model_training\n",
    "import numpy as np\n",
    "\n",
    "net_to_train = config['net_types'][1]\n",
    "net = NNet(net_type=net_to_train)\n",
    "single_model_training(model=net,\n",
    "                      save_path=config[net_to_train]['checkpoint'],\n",
    "                      additional_epochs=config['additional_epochs'],\n",
    "                      competition_epochs=config['competition_epochs'],\n",
    "                      b_size=config[net_to_train]['batch_size'],\n",
    "                      loss=config['loss'],\n",
    "                      l_rate_a=config['learning_rate_additional_data'],\n",
    "                      l_rate_b=config['learning_rate_competition_data'])\n",
    "\n",
    "predictions = net.predict_test_data()\n",
    "np.save(file=config[net_to_train]['predictions_path'], arr=predictions)\n",
    "print('saved model predictions at path: {}'.format(config[net_to_train]['predictions_path']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USPP-Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from config import config\n",
    "from model import NNet\n",
    "from utils import single_model_training\n",
    "import numpy as np\n",
    "\n",
    "net_to_train = config['net_types'][2]\n",
    "net = NNet(net_type=net_to_train)\n",
    "single_model_training(model=net,\n",
    "                      save_path=config[net_to_train]['checkpoint'],\n",
    "                      additional_epochs=config['additional_epochs'],\n",
    "                      competition_epochs=config['competition_epochs'],\n",
    "                      b_size=config[net_to_train]['batch_size'],\n",
    "                      loss=config['loss'],\n",
    "                      l_rate_a=config['learning_rate_additional_data'],\n",
    "                      l_rate_b=config['learning_rate_competition_data'])\n",
    "\n",
    "predictions = net.predict_test_data()\n",
    "np.save(file=config[net_to_train]['predictions_path'], arr=predictions)\n",
    "print('saved model predictions at path: {}'.format(config[net_to_train]['predictions_path']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from config import config\n",
    "from model import NNet\n",
    "from utils import single_model_training\n",
    "import numpy as np\n",
    "\n",
    "net_to_train = config['net_types'][3]\n",
    "net = NNet(net_type=net_to_train)\n",
    "single_model_training(model=net,\n",
    "                      save_path=config[net_to_train]['checkpoint'],\n",
    "                      additional_epochs=config['additional_epochs'],\n",
    "                      competition_epochs=config['competition_epochs'],\n",
    "                      b_size=config[net_to_train]['batch_size'],\n",
    "                      loss=config['loss'],\n",
    "                      l_rate_a=config['learning_rate_additional_data'],\n",
    "                      l_rate_b=config['learning_rate_competition_data'])\n",
    "\n",
    "predictions = net.predict_test_data()\n",
    "np.save(file=config[net_to_train]['predictions_path'], arr=predictions)\n",
    "print('saved model predictions at path: {}'.format(config[net_to_train]['predictions_path']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URES-ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from config import config\n",
    "from model import NNet\n",
    "from utils import single_model_training\n",
    "import numpy as np\n",
    "\n",
    "net_to_train = config['net_types'][4]\n",
    "net = NNet(net_type=net_to_train)\n",
    "single_model_training(model=net,\n",
    "                      save_path=config[net_to_train]['checkpoint'],\n",
    "                      additional_epochs=config['additional_epochs'],\n",
    "                      competition_epochs=config['competition_epochs'],\n",
    "                      b_size=config[net_to_train]['batch_size'],\n",
    "                      loss=config['loss'],\n",
    "                      l_rate_a=config['learning_rate_additional_data'],\n",
    "                      l_rate_b=config['learning_rate_competition_data'])\n",
    "\n",
    "predictions = net.predict_test_data()\n",
    "np.save(file=config[net_to_train]['predictions_path'], arr=predictions)\n",
    "print('saved model predictions at path: {}'.format(config[net_to_train]['predictions_path']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USPP-ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from config import config\n",
    "from model import NNet\n",
    "from utils import single_model_training\n",
    "import numpy as np\n",
    "\n",
    "net_to_train = config['net_types'][5]\n",
    "net = NNet(net_type=net_to_train)\n",
    "single_model_training(model=net,\n",
    "                      save_path=config[net_to_train]['checkpoint'],\n",
    "                      additional_epochs=config['additional_epochs'],\n",
    "                      competition_epochs=config['competition_epochs'],\n",
    "                      b_size=config[net_to_train]['batch_size'],\n",
    "                      loss=config['loss'],\n",
    "                      l_rate_a=config['learning_rate_additional_data'],\n",
    "                      l_rate_b=config['learning_rate_competition_data'])\n",
    "\n",
    "predictions = net.predict_test_data()\n",
    "np.save(file=config[net_to_train]['predictions_path'], arr=predictions)\n",
    "print('saved model predictions at path: {}'.format(config[net_to_train]['predictions_path']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We've now trained all the models we're interested to. Let's ensemble them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from config import config\n",
    "from model import NNet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for net_type in config['net_types']:\n",
    "    preds = np.load(config[net_type]['predictions_path'], allow_pickle=True)\n",
    "    predictions.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ensemble = np.mean(np.array(predictions), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file=config['final_predictions_path'], arr=mean_ensemble)\n",
    "print('saved final mean ensemble predictions at path: {}'.format(config['final_predictions_path']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = NNet()\n",
    "dummy_model.test_images_predictions = mean_ensemble\n",
    "mean_sub = dummy_model.create_submission_file(path=config['submission_path'], treshold=config['treshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the outputs\n",
    "dummy_model.display_test_predictions(config['submission_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save a figure containing all the predictions to visualize them later\n",
    "%%capture\n",
    "dummy_model.display_test_predictions(config['submission_path'], samples_number=94, figure_size=(20, 470))\n",
    "plt.savefig(config['figures_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We're done. All the outputs of the notebook can be found at `config['submission_path']`."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
